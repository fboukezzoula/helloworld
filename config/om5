Morning! Glad to hear the RIRs and aggregates are creating correctly based on your `config.yaml`â€”that's progress! ðŸ˜Š Thanks for the details on the issue; I see exactly what's happening and why the tags aren't unique per prefix.

### Understanding the Issue
- **Current Behavior**: The script matches aggregates at the *VNet level* (based on subscription name containing `match_criteria`). All address spaces for that VNet get the *same* aggregate and its tags. This works if all address spaces in a VNet belong to the same aggregate, but not when they need different ones (as in your example with 2 address spaces in different aggregates/RIRs).
- **Your Example**: For 1 VNet with 2 address spaces (e.g., "10.0.0.0/16" in "prod" aggregate with tags ["prod"], and "192.168.0.0/16" in "dev" aggregate with tags ["dev"]), both prefixes end up with the same tags because the matching is VNet-wide.
- **Root Cause**: The matching logic needs to be per *address space* (prefix), not per VNet. We should check which aggregate the specific prefix falls within (e.g., is "10.0.0.0/16" a subnet of the "10.0.0.0/8" aggregate?).

### Fixes in This Update
- **Per-Address-Space Matching**: Moved the aggregate matching inside the address_space loop. For each address space, it checks if it's a subnet of any aggregate's prefix (using Python's `ipaddress` module for accurate IP range checks).
  - If multiple aggregates match, it picks the first (you can refine to most specific if needed).
  - If no match, skips aggregate assignment (logs a warning).
- **Unique Tags per Prefix**: Each prefix now gets its own matched aggregate's tags copied, plus the sync tag and additional_tags.
- **RIR Handling**: Since aggregates are tied to RIRs, this indirectly assigns the correct RIR per prefix (NetBox enforces this via the aggregate).
- **New Import**: Added `import ipaddress` for range checks.
- **Logging**: Enhanced to show per-address-space matching (e.g., "Matched address space X to aggregate Y").
- **Config.yaml**: No changes neededâ€”your existing `aggregates` section works (e.g., no need for `match_criteria` anymore; it's now range-based).
- **Full Script**: Provided below, complete and ready to replace your current one. No other changes (e.g., custom fields still use only subscription name).

This should ensure each address space gets its own aggregate and unique tags copied from it.

### Full Updated Script
```python
#!/usr/bin/env python3

import os
import sys
import logging
import argparse
from pathlib import Path
import yaml
import re
import ipaddress  # New: For checking if prefix is within aggregate range
from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, ClientSecretCredential
from azure.mgmt.subscription import SubscriptionClient
from azure.mgmt.network import NetworkManagementClient
from azure.mgmt.managementgroups import ManagementGroupsAPI
from pynetbox import api
from pynetbox.core.query import RequestError
import requests

# Default logging config (can be overridden by YAML or CLI)
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_config_yaml(config_path='config.yaml'):
    """Load configuration from YAML file if it exists"""
    config = {}
    config_file = Path(config_path)
    if config_file.exists():
        try:
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
            logger.info(f"Loaded configuration from {config_path}")
        except yaml.YAMLError as e:
            logger.error(f"Error parsing {config_path}: {str(e)}")
        except Exception as e:
            logger.error(f"Error loading {config_path}: {str(e)}")
    else:
        logger.info(f"No {config_path} found; using defaults and CLI args")
    return config

def get_azure_credentials(config, args):
    """Get Azure credentials based on config and args"""
    auth_method = args.auth_method or config.get('azure', {}).get('authentication', {}).get('method', 'default')
    
    client_id = args.azure_client_id or config.get('azure', {}).get('authentication', {}).get('client_id')
    client_secret = args.azure_client_secret or config.get('azure', {}).get('authentication', {}).get('client_secret')
    tenant_id = args.azure_tenant_id or config.get('azure', {}).get('authentication', {}).get('tenant_id')
    
    if client_id and client_secret and tenant_id:
        logger.info("Using Azure Service Principal authentication")
        return ClientSecretCredential(
            tenant_id=tenant_id,
            client_id=client_id,
            client_secret=client_secret
        )
    elif auth_method == 'interactive':
        logger.info("Using interactive browser authentication for Azure")
        return InteractiveBrowserCredential()
    else:
        logger.info("Using default Azure credential chain")
        return DefaultAzureCredential()

def get_management_group_subscriptions(credential, management_group_id=None, management_group_name=None):
    logger.info("Getting subscriptions from management group")
    
    try:
        mg_client = ManagementGroupsAPI(credential)
        
        if management_group_name and not management_group_id:
            logger.info(f"Looking for management group with name: {management_group_name}")
            management_groups = mg_client.management_groups.list()
            for mg in management_groups:
                if mg.display_name == management_group_name:
                    management_group_id = mg.name
                    logger.info(f"Found management group ID: {management_group_id}")
                    break
            
            if not management_group_id:
                logger.error(f"Management group with name '{management_group_name}' not found")
                return []
        
        mg_details = mg_client.management_groups.get(
            group_id=management_group_id,
            expand="children",
            recurse=True
        )
        
        subscriptions = []
        
        def extract_subscriptions(mg_node):
            if hasattr(mg_node, 'children') and mg_node.children:
                for child in mg_node.children:
                    if child.type == "/subscriptions":
                        subscription_info = type('obj', (object,), {
                            'subscription_id': child.name,
                            'display_name': child.display_name
                        })
                        subscriptions.append(subscription_info)
                        logger.info(f"Found subscription: {child.display_name} ({child.name})")
                    elif child.type == "/providers/Microsoft.Management/managementGroups":
                        extract_subscriptions(child)
        
        extract_subscriptions(mg_details)
        
        logger.info(f"Found {len(subscriptions)} subscriptions in management group")
        return subscriptions
        
    except Exception as e:
        logger.error(f"Error getting subscriptions from management group: {str(e)}")
        return []

def get_azure_subscriptions(credential):
    logger.info("Getting Azure subscriptions")
    subscription_client = SubscriptionClient(credential)
    subscriptions = list(subscription_client.subscriptions.list())
    logger.info(f"Found {len(subscriptions)} subscriptions")
    return subscriptions

def get_vnets_and_subnets(subscription_id, credential):
    logger.info(f"Getting VNets for subscription {subscription_id}")
    network_client = NetworkManagementClient(credential, subscription_id)
    
    vnets = list(network_client.virtual_networks.list_all())
    logger.info(f"Found {len(vnets)} VNets in subscription {subscription_id}")
    
    vnet_data = []
    for vnet in vnets:
        address_spaces = [prefix for prefix in vnet.address_space.address_prefixes if prefix]  # Skip empty
        logger.debug(f"VNet {vnet.name} has {len(address_spaces)} address spaces: {address_spaces}")
        vnet_info = {
            'name': vnet.name,
            'id': vnet.id,
            'resource_group': vnet.id.split('/')[4],
            'location': vnet.location,
            'address_space': address_spaces
        }
        vnet_data.append(vnet_info)
    
    return vnet_data

def get_or_create_rir(nb, name, slug, description, is_private=False):
    try:
        rir = nb.ipam.rirs.get(slug=slug)
        if rir:
            logger.info(f"Found existing RIR: {name}")
            return rir
    except Exception as e:
        logger.debug(f"Error getting RIR {name}: {str(e)}")
    
    logger.info(f"Creating new RIR: {name}")
    return nb.ipam.rirs.create(
        name=name,
        slug=slug,
        description=description,
        is_private=is_private
    )

def get_or_create_aggregate(nb, prefix, rir_id, description, tags):
    try:
        aggregate = nb.ipam.aggregates.get(prefix=prefix)
        if aggregate:
            logger.info(f"Found existing aggregate: {prefix}")
            return aggregate
    except Exception as e:
        logger.debug(f"Error getting aggregate {prefix}: {str(e)}")
    
    logger.info(f"Creating new aggregate: {prefix}")
    return nb.ipam.aggregates.create(
        prefix=prefix,
        rir=rir_id,
        description=description,
        tags=tags
    )

def get_or_create_tag(nb, tag_name, tag_description=""):
    slug = tag_name.lower().replace(" ", "-")
    try:
        tag = nb.extras.tags.get(slug=slug)
        if tag:
            logger.info(f"Found existing tag: {tag_name}")
            return tag
    except Exception as e:
        logger.debug(f"Error getting tag {tag_name}: {str(e)}")
    
    logger.info(f"Creating new tag: {tag_name}")
    return nb.extras.tags.create(
        name=tag_name,
        slug=slug,
        description=tag_description
    )

def get_or_create_custom_field(nb, field_name, field_type, field_description, object_types, field_choices=None):
    try:
        custom_field = nb.extras.custom_fields.get(name=field_name)
        if custom_field:
            logger.info(f"Found existing custom field: {field_name}")
            return custom_field
    except Exception as e:
        logger.debug(f"Error getting custom field {field_name}: {str(e)}")

    logger.info(f"Creating new custom field: {field_name}")
    field_data = {
        'name': field_name,
        'label': field_name.replace('_', ' ').title(),
        'type': field_type,
        'description': field_description,
        'object_types': object_types,
        'required': False,
        'default': None
    }
    if field_choices:
        field_data['choices'] = field_choices

    return nb.extras.custom_fields.create(**field_data)

def get_or_create_prefix(nb, prefix_value, defaults, subscription_name=None, subscription_id=None, aggregate_id=None, tags=None):
    try:
        existing_prefixes = nb.ipam.prefixes.filter(prefix=prefix_value)
        
        if existing_prefixes:
            logger.info(f"Found existing prefix: {prefix_value}")
            prefix = list(existing_prefixes)[0]
            
            needs_update = False
            for key, value in defaults.items():
                if key == 'parent':  
                    continue
                current_value = getattr(prefix, key, None)
                if current_value != value:
                    setattr(prefix, key, value)
                    needs_update = True
            
            if subscription_name and subscription_id:
                custom_fields = getattr(prefix, 'custom_fields', {}) or {}
                azure_subscription_value = subscription_name
                
                existing_value = custom_fields.get('azure_subscription', '')
                if existing_value != azure_subscription_value or re.search(r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}', existing_value, re.IGNORECASE):
                    custom_fields['azure_subscription'] = azure_subscription_value
                    custom_fields['azure_subscription_url'] = f"https://portal.azure.com/#@/subscription/{subscription_id}/overview"
                    prefix.custom_fields = custom_fields
                    needs_update = True
                    logger.debug(f"Forced update of azure_subscription to clean value: {azure_subscription_value}")
            
            if aggregate_id and getattr(prefix, 'aggregate', None) != aggregate_id:
                prefix.aggregate = aggregate_id
                needs_update = True
            
            if tags and set(tag.id for tag in prefix.tags) != set(tag['id'] for tag in tags):
                prefix.tags = tags
                needs_update = True
            
            if needs_update:
                prefix.save()
                logger.info(f"Updated prefix: {prefix_value}")
                
            return prefix, False
    except AttributeError as e:
        logger.error(f"Attribute error when updating prefix {prefix_value}: {str(e)}")
    except Exception as e:
        logger.debug(f"Error checking for existing prefix {prefix_value}: {str(e)}")
    
    try:
        logger.info(f"Creating new prefix: {prefix_value}")
        
        if subscription_name and subscription_id:
            if 'custom_fields' not in defaults:
                defaults['custom_fields'] = {}
            defaults['custom_fields']['azure_subscription'] = subscription_name
            defaults['custom_fields']['azure_subscription_url'] = f"https://portal.azure.com/#@/subscription/{subscription_id}/overview"
        
        if aggregate_id:
            defaults['aggregate'] = aggregate_id
        if tags:
            defaults['tags'] = tags
        
        return nb.ipam.prefixes.create(
            prefix=prefix_value,
            **defaults
        ), True
    except RequestError as e:
        if "Duplicate prefix found" in str(e):
            logger.warning(f"Duplicate prefix found: {prefix_value}. Attempting to retrieve existing prefix.")
            try:
                existing_prefixes = nb.ipam.prefixes.filter(prefix=prefix_value)
                if existing_prefixes:
                    prefix = list(existing_prefixes)[0]
                    logger.info(f"Retrieved existing prefix: {prefix_value}")
                    return prefix, False
            except Exception as inner_e:
                logger.error(f"Error retrieving duplicate prefix {prefix_value}: {str(inner_e)}")
        raise

def setup_rirs_and_aggregates(nb, config):
    rirs_config = config.get('rirs', [])
    aggregates_config = config.get('aggregates', [])
    
    rir_map = {}
    for rir in rirs_config:
        created_rir = get_or_create_rir(
            nb,
            name=rir.get('name'),
            slug=rir.get('slug'),
            description=rir.get('description', ''),
            is_private=rir.get('is_private', False)
        )
        rir_map[rir['name']] = created_rir.id
    
    aggregate_map = {}
    for agg in aggregates_config:
        rir_id = rir_map.get(agg.get('rir'))
        if not rir_id:
            logger.error(f"RIR {agg.get('rir')} not found for aggregate {agg.get('prefix')}")
            continue
        
        agg_tags = []
        for tag_name in agg.get('tags', []):
            tag = get_or_create_tag(nb, tag_name)
            agg_tags.append({'id': tag.id})
        
        created_agg = get_or_create_aggregate(
            nb,
            prefix=agg.get('prefix'),
            rir_id=rir_id,
            description=agg.get('description', ''),
            tags=agg_tags
        )
        aggregate_map[agg.get('prefix')] = {
            'id': created_agg.id,
            'tags': agg_tags,
            'rir_id': rir_id  # Store for reference if needed
        }
    
    return aggregate_map

def setup_custom_fields(nb, config):
    logger.info("Setting up custom fields for Azure integration")
    custom_fields_config = config.get('custom_fields', {})
    
    try:
        if custom_fields_config.get('azure_subscription', {}).get('enabled', True):
            get_or_create_custom_field(
                nb,
                field_name="azure_subscription",
                field_type=custom_fields_config.get('azure_subscription', {}).get('field_type', 'text'),
                field_description=custom_fields_config.get('azure_subscription', {}).get('description', "Azure subscription name"),
                object_types=["ipam.prefix"]
            )
        
        if custom_fields_config.get('azure_subscription_url', {}).get('enabled', True):
            get_or_create_custom_field(
                nb,
                field_name="azure_subscription_url",
                field_type=custom_fields_config.get('azure_subscription_url', {}).get('field_type', 'url'),
                field_description=custom_fields_config.get('azure_subscription_url', {}).get('description', "Direct link to Azure subscription portal"),
                object_types=["ipam.prefix"]
            )
        logger.info("Custom fields setup completed")
    except Exception as e:
        logger.error(f"Error setting up custom fields: {str(e)}")

def sync_to_netbox(all_network_data, netbox_url, netbox_token, config):
    logger.info(f"Syncing data to Netbox at {netbox_url}")
    
    session = requests.Session()
    session.verify = config.get('ssl', {}).get('verify', True)
    session.timeout = config.get('timeouts', {}).get('netbox_api', 30)
    
    nb = api(netbox_url, token=netbox_token)
    nb.http_session = session
    
    setup_custom_fields(nb, config)
    
    aggregate_map = setup_rirs_and_aggregates(nb, config)
    
    sync_tag_config = config.get('tags', {}).get('sync_tag', {})
    azure_tag = get_or_create_tag(
        nb,
        tag_name=sync_tag_config.get('name', "azure-sync"),
        tag_description=sync_tag_config.get('description', "Synced from Azure")
    )
    azure_tag_dict = [{'id': azure_tag.id}]
    
    additional_tags = []
    for tag_name in config.get('tags', {}).get('additional_tags', []):
        tag = get_or_create_tag(nb, tag_name)
        additional_tags.append({'id': tag.id})
    
    for subscription_data in all_network_data:
        subscription_id = subscription_data['subscription_id']
        subscription_name = subscription_data['subscription_name']
        
        for vnet in subscription_data['vnets']:
            address_spaces = vnet['address_space']
            if not address_spaces:
                logger.warning(f"Skipping VNet {vnet['name']} (no address spaces)")
                continue
            
            logger.info(f"Processing VNet {vnet['name']} with {len(address_spaces)} address spaces")
            
            for idx, address_space in enumerate(address_spaces, 1):
                logger.debug(f"Syncing address space {idx}/{len(address_spaces)} for VNet {vnet['name']}: {address_space}")
                
                # New: Match aggregate per address space (check if it's a subnet of the aggregate's prefix)
                matching_aggregate = None
                try:
                    prefix_net = ipaddress.ip_network(address_space, strict=False)
                    for agg_prefix, agg_data in aggregate_map.items():
                        agg_net = ipaddress.ip_network(agg_prefix, strict=False)
                        if prefix_net.subnet_of(agg_net):
                            matching_aggregate = agg_data
                            logger.debug(f"Matched address space {address_space} to aggregate {agg_prefix}")
                            break
                except ValueError as e:
                    logger.warning(f"Invalid IP network for {address_space}: {str(e)}")
                    continue
                
                aggregate_id = matching_aggregate['id'] if matching_aggregate else None
                prefix_tags = azure_tag_dict + additional_tags
                if matching_aggregate:
                    prefix_tags += matching_aggregate['tags']  # Copy unique tags for this aggregate
                
                vnet_prefix, created = get_or_create_prefix(
                    nb,
                    address_space,
                    {
                        'description': f"Azure VNet: {vnet['name']} (Subscription: {subscription_id}) - Address Space {idx}",
                        'status': 'active',
                        'tags': prefix_tags
                    },
                    subscription_name=subscription_name,
                    subscription_id=subscription_id,
                    aggregate_id=aggregate_id,
                    tags=prefix_tags
                )
                
                action = "Created" if created else "Updated"
                logger.info(f"{action} prefix for VNet {vnet['name']} address space {idx}: {address_space} (Aggregate: {aggregate_id if aggregate_id else 'None'})")

def parse_arguments():
    parser = argparse.ArgumentParser(description='Sync Azure network data to Netbox')
    parser.add_argument('--netbox-url', help='Netbox URL')
    parser.add_argument('--netbox-token', help='Netbox API token')
    parser.add_argument('--auth-method', help='Azure auth method (default, interactive)')
    parser.add_argument('--subscription-id', help='Specific Azure subscription ID to process')
    parser.add_argument('--management-group-id', help='Azure Management Group ID')
    parser.add_argument('--management-group-name', help='Azure Management Group name')
    parser.add_argument('--azure-client-id', help='Azure Service Principal Client ID (appId)')
    parser.add_argument('--azure-client-secret', help='Azure Service Principal Client Secret')
    parser.add_argument('--azure-tenant-id', help='Azure Tenant ID')
    return parser.parse_args()

def main():
    config = load_config_yaml()
    
    args = parse_arguments()
    
    netbox_url = args.netbox_url or config.get('netbox', {}).get('url')
    netbox_token = args.netbox_token or config.get('netbox', {}).get('token')
    
    if not netbox_url or not netbox_token:
        logger.error("Netbox URL and token must be provided either as arguments or in config.yaml")
        sys.exit(1)
    
    log_level = config.get('logging', {}).get('level', 'DEBUG')
    log_format = config.get('logging', {}).get('format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logging.basicConfig(level=log_level, format=log_format)
    
    filters = config.get('filters', {})
    if filters.get('regions', {}).get('include'):
        logger.warning("Region include filters set but not implemented yet")
    
    try:
        logger.info("Starting Azure to Netbox sync")
        
        credential = get_azure_credentials(config, args)
        
        process_all = config.get('azure', {}).get('subscriptions', {}).get('process_all', True)
        specific_id = args.subscription_id or config.get('azure', {}).get('subscriptions', {}).get('specific_id')
        mg_id = args.management_group_id or config.get('azure', {}).get('subscriptions', {}).get('management_group', {}).get('id')
        mg_name = args.management_group_name or config.get('azure', {}).get('subscriptions', {}).get('management_group', {}).get('name')
        
        if mg_id or mg_name:
            subscriptions = get_management_group_subscriptions(credential, mg_id, mg_name)
            if not subscriptions:
                logger.error("No subscriptions found in the specified management group")
                sys.exit(1)
        elif specific_id:
            logger.info(f"Processing only subscription {specific_id}")
            sub_client = SubscriptionClient(credential)
            try:
                sub_details = sub_client.subscriptions.get(specific_id)
                real_display_name = sub_details.display_name
                logger.info(f"Retrieved real display name for subscription {specific_id}: {real_display_name}")
            except Exception as e:
                logger.warning(f"Could not retrieve display name for {specific_id}: {str(e)}. Using fallback.")
                real_display_name = f"Subscription {specific_id}"
            subscriptions = [type('obj', (object,), {
                'subscription_id': specific_id,
                'display_name': real_display_name
            })]
        elif process_all:
            subscriptions = get_azure_subscriptions(credential)
        else:
            logger.error("No subscription processing method specified")
            sys.exit(1)
        
        all_network_data = []
        
        for subscription in subscriptions:
            subscription_id = subscription.subscription_id
            subscription_data = {
                'subscription_id': subscription_id,
                'subscription_name': subscription.display_name,
                'vnets': []
            }
            
            vnets_data = get_vnets_and_subnets(subscription_id, credential)
            subscription_data['vnets'] = vnets_data
            all_network_data.append(subscription_data)
        
        sync_to_netbox(all_network_data, netbox_url, netbox_token, config)
        
        logger.info("Azure to Netbox sync completed successfully")
        
    except Exception as e:
        logger.error(f"Error during Azure to Netbox sync: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
```

### Testing Notes
- **For Your Example**: With aggregates like "10.0.0.0/8" (tags: ["prod"]) and "192.168.0.0/16" (tags: ["dev"]), a VNet with address spaces "10.1.0.0/16" and "192.168.1.0/24" should match them respectively. The first prefix gets ["prod"] (plus sync/additional), the second gets ["dev"].
- **Logs**: Look for "Matched address space X to aggregate Y" to confirm per-address-space matching.
- **Edge Cases**: If an address space matches multiple aggregates, it picks the first (order in `config.yaml` matters). If none match, logs "Aggregate: None".
- **Config.yaml**: Remove `match_criteria` from aggregates (it's no longer used; range-based now). Ensure aggregate prefixes are broad enough to contain your address spaces.

Test this version and let me know if the tags are now unique per prefix. If not, share sample logs/config snippets, and we'll refine! ðŸš€
