Absolutely! Here is the **entire script** with:

- Full config.yaml support
- Recursive management group traversal (with pretty-printed tree at DEBUG level)
- All your NetBox sync logic
- All previous improvements (tags, filters, etc.)

**You only need to install `pyyaml` if you havenâ€™t already:**
```sh
pip install pyyaml
```

---

```python
#!/usr/bin/env python3

import os
import sys
import logging
import argparse
import yaml
import re
import requests
from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential
from azure.mgmt.subscription import SubscriptionClient
from azure.mgmt.network import NetworkManagementClient
from azure.mgmt.compute import ComputeManagementClient
from azure.mgmt.managementgroups import ManagementGroupsAPI
from pynetbox import api
from pynetbox.core.query import RequestError

def load_config(config_path):
    try:
        with open(config_path, ' 'r') as f:
            return yaml.safe_load(f)
    except Exception as e:
        logging.error(f"Failed to load config file {config_path}: {str(e)}")
        sys.exit(1)

def setup_logging(config):
    level = getattr(logging, config['logging']['level'].upper(), logging.INFO)
    log_format = config['logging']['format']
    logging.basicConfig(level=level, format=log_format)
    return logging.getLogger(__name__)

def truncate_name(name, max_length):
    if '.' in name:
        name = name.split('.')[0]
        logger.debug(f"Removed decimal portion, new name: {name}")
    if len(name) > max_length:
        logger.warning(f"Name '{name}' exceeds {max_length} characters, truncating")
        name = name[:max_length]
    return name

def get_azure_credentials(method):
    if method == 'interactive':
        logger.info("Using interactive browser authentication for Azure")
        return InteractiveBrowserCredential()
    else:
        logger.info("Using default Azure credential chain")
        return DefaultAzureCredential()

def print_mg_tree(node, indent=0):
    """Pretty print the management group tree for debugging."""
    prefix = "  " * indent
    if hasattr(node, 'type'):
        if node.type.lower() == "/subscriptions":
            logger.debug(f"{prefix}- Subscription: {getattr(node, 'display_name', node.name)} ({node.name})")
        elif node.type.lower() == "/providers/microsoft.management/managementgroups":
            logger.debug(f"{prefix}- Management Group: {getattr(node, 'display_name', node.name)} ({node.name})")
    if hasattr(node, 'children') and node.children:
        for child in node.children:
            print_mg_tree(child, indent + 1)

def get_management_group_subscriptions(credential, management_group_id=None, management_group_name=None):
    """Get all subscriptions from a management group, recursively, and print the tree."""
    logger.info("Getting subscriptions from management group (recursive)")

    try:
        mg_client = ManagementGroupsAPI(credential)

        if management_group_name and not management_group_id:
            logger.info(f"Looking for management group with name: {management_group_name}")
            management_groups = mg_client.management_groups.list()
            for mg in management_groups:
                if mg.display_name == management_group_name:
                    management_group_id = mg.name
                    logger.info(f"Found management group ID: {management_group_id}")
                    break

            if not management_group_id:
                logger.error(f"Management group with name '{management_group_name}' not found")
                return []

        mg_details = mg_client.management_groups.get(
            group_id=management_group_id,
            expand="children",
            recurse=True
        )

        # Print the full tree for debugging
        logger.debug("Full Management Group Tree:")
        print_mg_tree(mg_details)

        subscriptions = []

        def extract_subscriptions(mg_node):
            if hasattr(mg_node, 'children') and mg_node.children:
                for child in mg_node.children:
                    if child.type.lower() == "/subscriptions":
                        subscription_info = type('obj', (object,), {
                            'subscription_id': child.name,
                            'display_name': getattr(child, 'display_name', child.name)
                        })
                        subscriptions.append(subscription_info)
                        logger.info(f"Found subscription: {getattr(child, 'display_name', child.name)} ({child.name})")
                    elif child.type.lower() == "/providers/microsoft.management/managementgroups":
                        extract_subscriptions(child)

        extract_subscriptions(mg_details)

        logger.info(f"Found {len(subscriptions)} subscriptions in management group (recursive)")
        return subscriptions

    except Exception as e:
        logger.error(f"Error getting subscriptions from management group: {str(e)}")
        return []

def get_azure_subscriptions(credential):
    logger.info("Getting Azure subscriptions")
    subscription_client = SubscriptionClient(credential)
    subscriptions = list(subscription_client.subscriptions.list())
    logger.info(f"Found {len(subscriptions)} subscriptions")
    return subscriptions

def get_vnets_and_subnets(subscription_id, credential):
    logger.info(f"Getting VNets and subnets for subscription {subscription_id}")
    network_client = NetworkManagementClient(credential, subscription_id)
    vnets = list(network_client.virtual_networks.list_all())
    logger.info(f"Found {len(vnets)} VNets in subscription {subscription_id}")
    vnet_data = []
    for vnet in vnets:
        vnet_info = {
            'name': vnet.name,
            'id': vnet.id,
            'resource_group': vnet.id.split('/')[4],
            'location': vnet.location,
            'address_space': [prefix for prefix in vnet.address_space.address_prefixes],
            'subnets': []
        }
        for subnet in vnet.subnets:
            subnet_info = {
                'name': subnet.name,
                'id': subnet.id,
                'address_prefix': subnet.address_prefix,
                'devices': []
            }
            vnet_info['subnets'].append(subnet_info)
        vnet_data.append(vnet_info)
    return vnet_data

def apply_filters(vnets_data, config):
    filtered_vnets = []
    regions_include = config['filters']['regions']['include']
    regions_exclude = config['filters']['regions']['exclude']
    rg_include = config['filters']['resource_groups']['include']
    rg_exclude = config['filters']['resource_groups']['exclude']
    name_include_patterns = [re.compile(p) for p in config['filters']['resource_names']['include_patterns']]
    name_exclude_patterns = [re.compile(p) for p in config['filters']['resource_names']['exclude_patterns']]

    for vnet in vnets_data:
        if regions_include and vnet['location'] not in regions_include:
            continue
        if vnet['location'] in regions_exclude:
            continue
        if rg_include and vnet['resource_group'] not in rg_include:
            continue
        if vnet['resource_group'] in rg_exclude:
            continue
        if name_include_patterns and not any(p.match(vnet['name']) for p in name_include_patterns):
            continue
        if any(p.match(vnet['name']) for p in name_exclude_patterns):
            continue
        filtered_subnets = []
        for subnet in vnet['subnets']:
            if name_include_patterns and not any(p.match(subnet['name']) for p in name_include_patterns):
                continue
            if any(p.match(subnet['name']) for p in name_exclude_patterns):
                continue
            filtered_subnets.append(subnet)
        if filtered_subnets:
            vnet['subnets'] = filtered_subnets
            filtered_vnets.append(vnet)
    logger.info(f"After filtering: {len(filtered_vnets)} VNets remaining")
    return filtered_vnets

def get_devices_in_subnet(subscription_id, credential, vnets_data):
    logger.info(f"Getting devices for subscription {subscription_id}")
    network_client = NetworkManagementClient(credential, subscription_id)
    compute_client = ComputeManagementClient(credential, subscription_id)
    nics = list(network_client.network_interfaces.list_all())
    logger.info(f"Found {len(nics)} network interfaces in subscription {subscription_id}")
    vms = list(compute_client.virtual_machines.list_all())
    logger.info(f"Found {len(vms)} virtual machines in subscription {subscription_id}")
    vm_dict = {vm.id: vm for vm in vms}
    for nic in nics:
        logger.debug(f"Processing NIC: {nic.name} (ID: {nic.id})")
        if nic.ip_configurations:
            for ip_config in nic.ip_configurations:
                if ip_config.subnet:
                    subnet_id = ip_config.subnet.id
                    for vnet in vnets_data:
                        for subnet in vnet['subnets']:
                            if subnet['id'] == subnet_id:
                                vm = None
                                if nic.virtual_machine:
                                    vm_id = nic.virtual_machine.id
                                    vm = vm_dict.get(vm_id)
                                device_info = {
                                    'name': vm.name if vm else nic.name,
                                    'id': vm.id if vm else nic.id,
                                    'type': 'vm' if vm else 'network_interface',
                                    'ip_address': ip_config.private_ip_address,
                                    'mac_address': nic.mac_address,
                                    'resource_group': nic.id.split('/')[4],
                                    'location': nic.location,
                                    'os_type': vm.storage_profile.os_disk.os_type if vm else None
                                }
                                logger.debug(f"Device info: {device_info}")
                                subnet['devices'].append(device_info)
    return vnets_data

def get_or_create_tag(nb, tag_name, tag_slug, tag_description):
    try:
        tag = nb.extras.tags.get(slug=tag_slug)
        if tag:
            logger.info(f"Found existing tag: {tag_slug}")
            return tag
    except Exception as e:
        logger.debug(f"Error getting tag {tag_slug}: {str(e)}")
    logger.info(f"Creating new tag: {tag_slug}")
    return nb.extras.tags.create(
        name=tag_name,
        slug=tag_slug,
        description=tag_description
    )

def get_or_create_custom_field(nb, field_name, field_type, field_description, object_types, field_choices=None):
    try:
        custom_field = nb.extras.custom_fields.get(name=field_name)
        if custom_field:
            logger.info(f"Found existing custom field: {field_name}")
            return custom_field
    except Exception as e:
        logger.debug(f"Error getting custom field {field_name}: {str(e)}")
    logger.info(f"Creating new custom field: {field_name}")
    field_data = {
        'name': field_name,
        'label': field_name.replace('_', ' ').title(),
        'type': field_type,
        'description': field_description,
        'object_types': object_types,
        'required': False,
        'default': None
    }
    if field_choices:
        field_data['choices'] = field_choices
    return nb.extras.custom_fields.create(**field_data)

def get_or_create_prefix(nb, prefix_value, defaults, subscription_name=None, subscription_id=None):
    try:
        existing_prefixes = nb.ipam.prefixes.filter(prefix=prefix_value)
        if existing_prefixes:
            logger.info(f"Found existing prefix: {prefix_value}")
            prefix = list(existing_prefixes)[0]
            needs_update = False
            for key, value in defaults.items():
                if getattr(prefix, key) != value:
                    setattr(prefix, key, value)
                    needs_update = True
            if subscription_name and subscription_id:
                custom_fields = getattr(prefix, 'custom_fields', {}) or {}
                azure_subscription_value = f"{subscription_name} - {subscription_id}"
                azure_subscription_url = f"https://portal.azure.com/#@/subscription/{subscription_id}/overview"
                if (custom_fields.get('azure_subscription') != azure_subscription_value or
                    custom_fields.get('azure_subscription_url') != azure_subscription_url):
                    custom_fields['azure_subscription'] = azure_subscription_value
                    custom_fields['azure_subscription_url'] = azure_subscription_url
                    prefix.custom_fields = custom_fields
                    needs_update = True
            if needs_update:
                prefix.save()
                logger.info(f"Updated prefix: {prefix_value}")
            return prefix, False
    except Exception as e:
        logger.debug(f"Error checking for existing prefix {prefix_value}: {str(e)}")
    try:
        logger.info(f"Creating new prefix: {prefix_value}")
        if subscription_name and subscription_id:
            if 'custom_fields' not in defaults:
                defaults['custom_fields'] = {}
            defaults['custom_fields']['azure_subscription'] = f"{subscription_name} - {subscription_id}"
            defaults['custom_fields']['azure_subscription_url'] = f"https://portal.azure.com/#@/subscription/{subscription_id}/overview"
        return nb.ipam.prefixes.create(
            prefix=prefix_value,
            **defaults
        ), True
    except RequestError as e:
        if "Duplicate prefix found" in str(e):
            logger.warning(f"Duplicate prefix found: {prefix_value}. Attempting to retrieve existing prefix.")
            try:
                existing_prefixes = nb.ipam.prefixes.filter(prefix=prefix_value)
                if existing_prefixes:
                    prefix = list(existing_prefixes)[0]
                    logger.info(f"Retrieved existing prefix: {prefix_value}")
                    return prefix, False
            except Exception as inner_e:
                logger.error(f"Error retrieving duplicate prefix {prefix_value}: {str(inner_e)}")
        raise

def get_or_create_device_type(nb, model, manufacturer_name, tags):
    try:
        device_type = nb.dcim.device_types.get(model=model)
        if device_type:
            logger.info(f"Found existing device type: {model}")
            return device_type
    except RequestError as e:
        logger.debug(f"Error getting device type {model}: {str(e)}")
    try:
        manufacturer = nb.dcim.manufacturers.get(name=manufacturer_name)
        if manufacturer:
            logger.info(f"Found existing manufacturer: {manufacturer_name}")
        else:
            manufacturer = nb.dcim.manufacturers.create(
                name=manufacturer_name,
                slug=manufacturer_name.lower().replace(" ", "-"),
                description='Created by Azure sync script'
            )
            logger.info(f"Created new manufacturer: {manufacturer_name}")
        manufacturer_id = manufacturer.id
    except RequestError as e:
        logger.error(f"Failed to get or create manufacturer {manufacturer_name}: {str(e)}")
        raise
    model_slug = model.lower().replace(" ", "-")
    try:
        device_type = nb.dcim.device_types.create(
            model=model,
            manufacturer=manufacturer_id,
            slug=model_slug,
            tags=tags
        )
        logger.info(f"Created new device type: {model}")
        return device_type
    except RequestError as e:
        logger.error(f"Failed to create device type {model}: {str(e)}")
        raise

def get_or_create_device_role(nb, name, vm_role, tags):
    try:
        role = nb.dcim.device_roles.get(name=name)
        if role:
            logger.info(f"Found existing device role: {name}")
            return role
    except RequestError as e:
        logger.debug(f"Error getting device role {name}: {str(e)}")
    try:
        role = nb.dcim.device_roles.create(
            name=name,
            slug=name.lower().replace(" ", "-"),
            vm_role=vm_role,
            tags=tags
        )
        logger.info(f"Created new device role: {name}")
        return role
    except RequestError as e:
        logger.error(f"Failed to create device role {name}: {str(e)}")
        raise

def get_or_create_site(nb, name, description, tags):
    try:
        site = nb.dcim.sites.get(name=name)
        if site:
            return site
    except Exception as e:
        logger.debug(f"Error getting site {name}: {str(e)}")
    return nb.dcim.sites.create(
        name=name,
        status='active',
        slug=name.lower().replace(" ", "-"),
        description=description,
        tags=tags
    )

def setup_custom_fields(nb, config):
    logger.info("Setting up custom fields for Azure integration")
    try:
        cf = config['custom_fields']
        if cf['azure_subscription']['enabled']:
            get_or_create_custom_field(
                nb,
                field_name="azure_subscription",
                field_type=cf['azure_subscription']['field_type'],
                field_description=cf['azure_subscription']['description'],
                object_types=["ipam.prefix"]
            )
        if cf['azure_subscription_url']['enabled']:
            get_or_create_custom_field(
                nb,
                field_name="azure_subscription_url",
                field_type=cf['azure_subscription_url']['field_type'],
                field_description=cf['azure_subscription_url']['description'],
                object_types=["ipam.prefix"]
            )
        logger.info("Custom fields setup completed")
    except Exception as e:
        logger.error(f"Error setting up custom fields: {str(e)}")

def sync_to_netbox(all_network_data, config, nb):
    mapping = config['mapping']
    tags_config = config['tags']
    sync_tag = get_or_create_tag(
        nb,
        tag_name=tags_config['sync_tag']['name'],
        tag_slug=tags_config['sync_tag']['name'].lower().replace(" ", "-"),
        tag_description=tags_config['sync_tag']['description']
    )
    sync_tag_dict = [{'id': sync_tag.id}]
    additional_tag_dicts = []
    for tag_slug in tags_config['additional_tags']:
        tag = get_or_create_tag(
            nb,
            tag_name=tag_slug.capitalize(),
            tag_slug=tag_slug,
            tag_description=f"Additional tag: {tag_slug}"
        )
        additional_tag_dicts.append({'id': tag.id})
    for subscription_data in all_network_data:
        subscription_id = subscription_data['subscription_id']
        subscription_name = subscription_data['subscription_name']
        env_slug = None
        sub_name_lower = subscription_name.lower()
        if 'dev' in sub_name_lower:
            env_slug = 'dev'
        elif 'hml' in sub_name_lower:
            env_slug = 'hml'
        elif 'uat' in sub_name_lower:
            env_slug = 'uat'
        elif 'prd' in sub_name_lower:
            env_slug = 'prd'
        env_tag_dict = []
        if env_slug:
            env_tag = get_or_create_tag(
                nb,
                tag_name=env_slug.upper(),
                tag_slug=env_slug,
                tag_description=f"Environment: {env_slug.upper()}"
            )
            env_tag_dict = [{'id': env_tag.id}]
            logger.info(f"Detected environment '{env_slug}' for subscription '{subscription_name}'")
        else:
            logger.warning(f"No environment detected in subscription name '{subscription_name}'; skipping environment tag")
        sub_tags = sync_tag_dict + additional_tag_dicts + env_tag_dict
        for vnet in subscription_data['vnets']:
            location_slug = vnet['location'].lower().replace(' ', '')
            location_tag = get_or_create_tag(
                nb,
                tag_name=location_slug.capitalize(),
                tag_slug=location_slug,
                tag_description=f"Azure region: {vnet['location']}"
            )
            location_tag_dict = [{'id': location_tag.id}]
            vnet_tags = sub_tags + location_tag_dict
            for address_space in vnet['address_space']:
                vnet_prefix, created = get_or_create_prefix(
                    nb,
                    address_space,
                    {
                        'description': f"Azure VNet: {vnet['name']} (Subscription: {subscription_id})",
                        'status': 'active',
                        'tags': vnet_tags
                    },
                    subscription_name=subscription_name,
                    subscription_id=subscription_id
                )
                action = "Created" if created else "Updated"
                logger.info(f"{action} prefix for VNet {vnet['name']}: {address_space}")
                for subnet in vnet['subnets']:
                    if not subnet.get('address_prefix'):
                        logger.warning(f"Skipping subnet '{subnet.get('name')}' in VNet '{vnet['name']}' (no address_prefix)")
                        continue
                    subnet_prefix, created = get_or_create_prefix(
                        nb,
                        subnet['address_prefix'],
                        {
                            'description': f"Azure Subnet: {subnet['name']} (VNet: {vnet['name']})",
                            'status': 'active',
                            'tags': vnet_tags,
                            'parent': vnet_prefix.id
                        },
                        subscription_name=subscription_name,
                        subscription_id=subscription_id
                    )
                    action = "Created" if created else "Updated"
                    logger.info(f"{action} prefix for subnet {subnet['name']}: {subnet['address_prefix']}")
                    for device in subnet['devices']:
                        device_type_model = f"{mapping['device_type_prefix']} {device['type'].title()}"
                        device_type = get_or_create_device_type(
                            nb,
                            model=device_type_model,
                            manufacturer_name=mapping['manufacturer'],
                            tags=sync_tag_dict
                        )
                        device_role_name = f"{mapping['device_role_prefix']} {device['type'].title()}"
                        device_role = get_or_create_device_role(
                            nb,
                            name=device_role_name,
                            vm_role=device['type'] == 'vm',
                            tags=sync_tag_dict
                        )
                        site_name = f"{mapping['site_prefix']}{device['location']}"
                        site = get_or_create_site(
                            nb,
                            name=site_name,
                            description=f"Azure Region: {device['location']}",
                            tags=sync_tag_dict
                        )
                        device_name = truncate_name(device['name'], mapping['max_name_length'])
                        nb_device = nb.dcim.devices.get(name=device_name, site_id=site.id)
                        if nb_device:
                            logger.info(f"Found existing device: {device_name}")
                        else:
                            try:
                                nb_device = nb.dcim.devices.create(
                                    name=device_name,
                                    device_type=device_type.id,
                                    role=device_role.id,
                                    site=site.id,
                                    status='active',
                                    tags=sync_tag_dict
                                )
                                logger.info(f"Created new device: {device_name}")
                            except RequestError as e:
                                if "Device name must be unique per site" in str(e):
                                    suffix = 1
                                    while True:
                                        unique_name = f"{device_name}-{suffix}"
                                        if len(unique_name) > mapping['max_name_length']:
                                            unique_name = f"{device_name[:mapping['max_name_length']-len(str(suffix))-1]}-{suffix}"
                                        try:
                                            nb_device = nb.dcim.devices.create(
                                                name=unique_name,
                                                device_type=device_type.id,
                                                role=device_role.id,
                                                site=site.id,
                                                status='active',
                                                tags=sync_tag_dict
                                            )
                                            logger.info(f"Created new device with unique name: {unique_name}")
                                            break
                                        except RequestError as inner_e:
                                            if "Device name must be unique per site" in str(inner_e):
                                                suffix += 1
                                            else:
                                                raise
                                else:
                                    raise
                        interface_name = mapping['default_interface']
                        interface = nb.dcim.interfaces.get(device_id=nb_device.id, name=interface_name)
                        if interface:
                            logger.info(f"Found existing interface {interface_name} for device {device_name}")
                        else:
                            interface = nb.dcim.interfaces.create(
                                device=nb_device.id,
                                name=interface_name,
                                type="virtual",
                                mac_address=device['mac_address'] if device['mac_address'] else None,
                                tags=sync_tag_dict
                            )
                            logger.info(f"Created interface {interface_name} for device {device_name}")
                        ip_address = nb.ipam.ip_addresses.get(address=f"{device['ip_address']}/32")
                        if ip_address:
                            logger.info(f"Found existing IP address for {device_name}: {device['ip_address']}")
                            if ip_address.assigned_object_id != interface.id or ip_address.assigned_object_type != 'dcim.interface':
                                ip_address.assigned_object_id = interface.id
                                ip_address.assigned_object_type = 'dcim.interface'
                                ip_address.save()
                                logger.info(f"Updated IP address assignment for {device_name}")
                        else:
                            ip_address = nb.ipam.ip_addresses.create(
                                address=f"{device['ip_address']}/32",
                                description=f"IP for {device_name}",
                                status='active',
                                tags=sync_tag_dict,
                                assigned_object_type='dcim.interface',
                                assigned_object_id=interface.id
                            )
                            logger.info(f"Created new IP address for {device_name}: {device['ip_address']}")

def parse_arguments():
    parser = argparse.ArgumentParser(description='Sync Azure network data to Netbox')
    parser.add_argument('--config', help='Path to config YAML file', default='./config.yaml')
    return parser.parse_args()

def main():
    args = parse_arguments()
    config = load_config(args.config)
    global logger
    logger = setup_logging(config)
    netbox_url = config['netbox']['url']
    netbox_token = config['netbox']['token']
    if not netbox_url or not netbox_token:
        logger.error("Netbox URL and token must be provided in config")
        sys.exit(1)
    try:
        logger.info("Starting Azure to Netbox sync")
        credential = get_azure_credentials(config['azure']['authentication']['method'])
        azure_subs = config['azure']['subscriptions']
        if azure_subs.get('process_all', False):
            subscriptions = get_azure_subscriptions(credential)
        elif 'specific_id' in azure_subs and azure_subs['specific_id']:
            logger.info(f"Fetching details for specific subscription {azure_subs['specific_id']}")
            subscription_client = SubscriptionClient(credential)
            try:
                sub = subscription_client.subscriptions.get(azure_subs['specific_id'])
                subscriptions = [type('obj', (object,), {
                    'subscription_id': sub.subscription_id,
                    'display_name': sub.display_name
                })]
                logger.info(f"Found subscription: {sub.display_name} ({sub.subscription_id})")
            except Exception as e:
                logger.error(f"Failed to fetch subscription {azure_subs['specific_id']}: {str(e)}")
                sys.exit(1)
        elif 'management_group' in azure_subs:
            mg = azure_subs['management_group']
            subscriptions = get_management_group_subscriptions(
                credential, 
                mg.get('id'), 
                mg.get('name')
            )
            if not subscriptions:
                logger.error("No subscriptions found in the specified management group")
                sys.exit(1)
        else:
            logger.error("No valid subscription configuration provided")
            sys.exit(1)
        all_network_data = []
        for subscription in subscriptions:
            subscription_id = subscription.subscription_id
            subscription_data = {
                'subscription_id': subscription_id,
                'subscription_name': subscription.display_name,
                'vnets': []
            }
            vnets_data = get_vnets_and_subnets(subscription_id, credential)
            vnets_data = apply_filters(vnets_data, config)
            vnets_with_devices = get_devices_in_subnet(subscription_id, credential, vnets_data)
            if not any(subnet['devices'] for vnet in vnets_with_devices for subnet in vnet['subnets']):
                logger.warning("No devices found; adding fake one for testing")
                if vnets_with_devices and vnets_with_devices[0]['subnets']:
                    fake_device = {
                        'name': 'test-vm',
                        'id': '/fake/id',
                        'type': 'vm',
                        'ip_address': '10.0.0.99',
                        'mac_address': '00:11:22:33:44:55',
                        'resource_group': 'fake-rg',
                        'location': 'westeurope',
                        'os_type': 'Linux'
                    }
                    vnets_with_devices[0]['subnets'][0]['devices'].append(fake_device)
            subscription_data['vnets'] = vnets_with_devices
            all_network_data.append(subscription_data)
        nb = api(netbox_url, token=netbox_token)
        session = requests.Session()
        session.verify = config['ssl']['verify']
        session.timeout = config['timeouts']['netbox_api']
        nb.http_session = session
        setup_custom_fields(nb, config)
        sync_to_netbox(all_network_data, config, nb)
        logger.info("Azure to Netbox sync completed successfully")
    except Exception as e:
        logger.error(f"Error during Azure to Netbox sync: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

**How to use:**
- Place your `config.yaml` in the same directory or specify with `--config`.
- Set `logging.level: "DEBUG"` in your YAML to see the full management group tree in logs.
- Run:  
  ```sh
  python azure-sync.py --config /path/to/config.yaml
  ```

---

**Let me know if you want a minimal test config or further customization!**
