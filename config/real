### Explanation
- **Script Update**: I've added debug logging to `extract_subscriptions` to print the node type and name during recursion. This will help you verify if the hierarchy is being traversed (e.g., logs like "Processing node: /providers/Microsoft.Management/managementGroups - managementgroup2", then subscriptions under it). Run with `logging.level: "DEBUG"` to see these.
- **No Other Changes**: The recursion is already implemented correctly. If you still get the error, check:
  - Credentials have "Management Group Reader" role on the parent MG.
  - The MG ID/name is exact (case-sensitive for names).
  - Azure SDK version (ensure `azure-mgmt-managementgroups` is up to date: `pip install azure-mgmt-managementgroups --upgrade`).
- **Testing**: Specify the parent MG and check logs for "Found subscription: <name> (<id>)" for all nested subs.

### Full Script (With Added Debug Logging)
```python
#!/usr/bin/env python3

import os
import sys
import logging
import argparse
from pathlib import Path
import yaml
import re
import ipaddress
from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, ClientSecretCredential
from azure.mgmt.subscription import SubscriptionClient
from azure.mgmt.network import NetworkManagementClient
from azure.mgmt.managementgroups import ManagementGroupsAPI
from pynetbox import api
from pynetbox.core.query import RequestError
import requests

# Default logging config (can be overridden by YAML or CLI)
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_config_yaml(config_path='config.yaml'):
    """Load configuration from YAML file if it exists"""
    config = {}
    config_file = Path(config_path)
    if config_file.exists():
        try:
            with open(config_file, 'r') as f:
                config = yaml.safe_load(f)
            logger.info(f"Loaded configuration from {config_path}")
        except yaml.YAMLError as e:
            logger.error(f"Error parsing {config_path}: {str(e)}")
        except Exception as e:
            logger.error(f"Error loading {config_path}: {str(e)}")
    else:
        logger.info(f"No {config_path} found; using defaults and CLI args")
    return config

def get_azure_credentials(config, args):
    """Get Azure credentials based on config and args"""
    auth_method = args.auth_method or config.get('azure', {}).get('authentication', {}).get('method', 'default')
    
    client_id = args.azure_client_id or config.get('azure', {}).get('authentication', {}).get('client_id')
    client_secret = args.azure_client_secret or config.get('azure', {}).get('authentication', {}).get('client_secret')
    tenant_id = args.azure_tenant_id or config.get('azure', {}).get('authentication', {}).get('tenant_id')
    
    if client_id and client_secret and tenant_id:
        logger.info("Using Azure Service Principal authentication")
        return ClientSecretCredential(
            tenant_id=tenant_id,
            client_id=client_id,
            client_secret=client_secret
        )
    elif auth_method == 'interactive':
        logger.info("Using interactive browser authentication for Azure")
        return InteractiveBrowserCredential()
    else:
        logger.info("Using default Azure credential chain")
        return DefaultAzureCredential()

def get_management_group_subscriptions(credential, management_group_id=None, management_group_name=None):
    logger.info("Getting subscriptions from management group")
    
    try:
        mg_client = ManagementGroupsAPI(credential)
        
        if management_group_name and not management_group_id:
            logger.info(f"Looking for management group with name: {management_group_name}")
            management_groups = mg_client.management_groups.list()
            for mg in management_groups:
                if mg.display_name == management_group_name:
                    management_group_id = mg.name
                    logger.info(f"Found management group ID: {management_group_id}")
                    break
            
            if not management_group_id:
                logger.error(f"Management group with name '{management_group_name}' not found")
                return []
        
        mg_details = mg_client.management_groups.get(
            group_id=management_group_id,
            expand="children",
            recurse=True
        )
        
        subscriptions = []
        
        def extract_subscriptions(mg_node):
            logger.debug(f"Processing node: {mg_node.type} - {mg_node.name if hasattr(mg_node, 'name') else 'root'}")  # Added debug logging
            if hasattr(mg_node, 'children') and mg_node.children:
                for child in mg_node.children:
                    if child.type == "/subscriptions":
                        subscription_info = type('obj', (object,), {
                            'subscription_id': child.name,
                            'display_name': child.display_name
                        })
                        subscriptions.append(subscription_info)
                        logger.info(f"Found subscription: {child.display_name} ({child.name})")
                    elif child.type == "/providers/Microsoft.Management/managementGroups":
                        extract_subscriptions(child)
        
        extract_subscriptions(mg_details)
        
        logger.info(f"Found {len(subscriptions)} subscriptions in management group")
        return subscriptions
        
    except Exception as e:
        logger.error(f"Error getting subscriptions from management group: {str(e)}")
        return []

def get_azure_subscriptions(credential):
    logger.info("Getting Azure subscriptions")
    subscription_client = SubscriptionClient(credential)
    subscriptions = list(subscription_client.subscriptions.list())
    logger.info(f"Found {len(subscriptions)} subscriptions")
    return subscriptions

def get_vnets_and_subnets(subscription_id, credential):
    logger.info(f"Getting VNets for subscription {subscription_id}")
    network_client = NetworkManagementClient(credential, subscription_id)
    
    vnets = list(network_client.virtual_networks.list_all())
    logger.info(f"Found {len(vnets)} VNets in subscription {subscription_id}")
    
    vnet_data = []
    for vnet in vnets:
        address_spaces = [prefix for prefix in vnet.address_space.address_prefixes if prefix]  # Skip empty
        logger.debug(f"VNet {vnet.name} has {len(address_spaces)} address spaces: {address_spaces}")
        vnet_info = {
            'name': vnet.name,
            'id': vnet.id,
            'resource_group': vnet.id.split('/')[4],
            'location': vnet.location,
            'address_space': address_spaces
        }
        vnet_data.append(vnet_info)
    
    return vnet_data

def get_vnet_peerings(network_client, resource_group, vnet_name, config):
    """Fetch peerings for a VNet and format the 'Peering check' string"""
    peering_config = config.get('peering', {})
    if not peering_config.get('enabled', True):
        return "Peering check disabled"
    
    ok_value = peering_config.get('ok_value', '✅')  # Updated default to emoji
    ko_value = peering_config.get('ko_value', '❌')  # Updated default to emoji
    no_peerings = peering_config.get('no_peerings_value', 'No peerings')
    
    try:
        peerings = list(network_client.virtual_network_peerings.list(resource_group, vnet_name))
        if not peerings:
            return no_peerings
        
        peering_strs = []
        for peering in peerings:
            sync_status = peering.peering_sync_level if hasattr(peering, 'peering_sync_level') else 'Unknown'
            state = peering.peering_state if hasattr(peering, 'peering_state') else 'Unknown'
            
            logger.debug(f"Raw sync_status for {peering.name}: {sync_status}, state: {state}")  # Log raw values
            
            sync_ok = ok_value if sync_status == 'FullyInSync' else ko_value
            state_ok = ok_value if state == 'Connected' else ko_value
            
            peering_strs.append(f"name: {peering.name} - {sync_status} {sync_ok} - Peering state {state} {state_ok}")
        
        return "; ".join(peering_strs)
    except Exception as e:
        logger.warning(f"Error fetching peerings for VNet {vnet_name}: {str(e)}")
        return "Error fetching peerings"

def get_or_create_rir(nb, name, slug, description, is_private=False, tags=None):
    try:
        rir = nb.ipam.rirs.get(slug=slug)
        if rir:
            logger.info(f"Found existing RIR: {name}")
            return rir
    except Exception as e:
        logger.debug(f"Error getting RIR {name}: {str(e)}")
    
    logger.info(f"Creating new RIR: {name}")
    tag_dicts = tags or []
    return nb.ipam.rirs.create(
        name=name,
        slug=slug,
        description=description,
        is_private=is_private,
        tags=tag_dicts
    )

def get_or_create_aggregate(nb, prefix, rir_id, description, tags):
    try:
        aggregate = nb.ipam.aggregates.get(prefix=prefix)
        if aggregate:
            logger.info(f"Found existing aggregate: {prefix}")
            return aggregate
    except Exception as e:
        logger.debug(f"Error getting aggregate {prefix}: {str(e)}")
    
    logger.info(f"Creating new aggregate: {prefix}")
    return nb.ipam.aggregates.create(
        prefix=prefix,
        rir=rir_id,
        description=description,
        tags=tags
    )

def clean_color(color_str, default="aaaaaa"):
    """Clean and validate a color string (strip #, ensure 6 hex digits)"""
    if not isinstance(color_str, str):
        logger.warning(f"Invalid color type: {type(color_str)}; using default {default}")
        return default
    color_str = color_str.strip().lstrip('#').lower()
    if re.match(r'^[0-9a-f]{6}$', color_str):
        return color_str
    logger.warning(f"Invalid color format '{color_str}'; using default {default}")
    return default

def get_or_create_tag(nb, tag_input, tag_description="", tag_color="aaaaaa"):
    if isinstance(tag_input, dict):
        logger.debug("Tag input is a dict; extracting properties.")
        tag_name = tag_input.get('name')
        if not tag_name:
            logger.error("Tag dict missing 'name' key; skipping this tag.")
            return None  # Skip instead of raising to prevent crash
        tag_description = tag_input.get('description', tag_description)
        tag_color = clean_color(tag_input.get('color', tag_color))
    elif isinstance(tag_input, str):
        tag_name = tag_input
        tag_color = clean_color(tag_color)  # Use passed or default
    else:
        logger.error(f"Invalid tag_input type: {type(tag_input)}. Must be str or dict; skipping.")
        return None

    slug = tag_name.lower().replace(" ", "-")
    try:
        tag = nb.extras.tags.get(slug=slug)
        if tag:
            needs_update = False
            if tag.description != tag_description:
                tag.description = tag_description
                needs_update = True
            if tag.color != tag_color:
                tag.color = tag_color
                needs_update = True
            if needs_update:
                tag.save()
                logger.info(f"Updated existing tag: {tag_name} (color: {tag_color})")
            else:
                logger.info(f"Found existing tag: {tag_name} (color: {tag.color})")
            return tag
    except Exception as e:
        logger.debug(f"Error getting tag {tag_name}: {str(e)}")
    
    logger.info(f"Creating new tag: {tag_name} (color: {tag_color})")
    try:
        return nb.extras.tags.create(
            name=tag_name,
            slug=slug,
            description=tag_description,
            color=tag_color
        )
    except Exception as e:
        logger.error(f"Failed to create tag {tag_name}: {str(e)}")
        return None

def get_or_create_ipam_role(nb, name, slug, description, tags):
    try:
        role = nb.ipam.roles.get(slug=slug)
        if role:
            logger.info(f"Found existing IPAM role: {name}")
            return role
    except Exception as e:
        logger.debug(f"Error getting IPAM role {name}: {str(e)}")
    
    logger.info(f"Creating new IPAM role: {name}")
    tag_dicts = [t for t in tags if isinstance(t, dict) and 'id' in t]  # Filter valid dicts
    return nb.ipam.roles.create(
        name=name,
        slug=slug,
        description=description,
        tags=tag_dicts
    )

def get_or_create_tenant_group(nb, name, slug, description=""):
    try:
        group = nb.tenancy.tenant_groups.get(slug=slug)
        if group:
            logger.info(f"Found existing Tenant Group: {name}")
            return group
    except Exception as e:
        logger.debug(f"Error getting Tenant Group {name}: {str(e)}")
    
    logger.info(f"Creating new Tenant Group: {name}")
    return nb.tenancy.tenant_groups.create(
        name=name,
        slug=slug,
        description=description
    )

def get_or_create_tenant(nb, name, group_id, description="", tags=None):
    slug = name.lower().replace(' ', '-')  # Generate slug from name (UUID is already suitable)
    try:
        tenant = nb.tenancy.tenants.get(slug=slug)
        if tenant:
            needs_update = False
            if tenant.group.id != group_id:
                tenant.group = group_id
                needs_update = True
            if tenant.description != description:
                tenant.description = description
                needs_update = True
            if tags and set(tag.id for tag in tenant.tags) != set(tag['id'] for tag in tags):
                tenant.tags = tags
                needs_update = True
            if needs_update:
                tenant.save()
                logger.info(f"Updated Tenant: {name}")
            else:
                logger.info(f"Found existing Tenant: {name}")
            return tenant
    except RequestError as e:
        logger.debug(f"Request error getting Tenant {name}: {str(e)}")
    except Exception as e:
        logger.debug(f"Error getting Tenant {name}: {str(e)}")
    
    logger.info(f"Creating new Tenant: {name} with slug {slug}")
    try:
        return nb.tenancy.tenants.create(
            name=name,
            slug=slug,  # Required field
            group=group_id,
            description=description,
            tags=tags or []
        )
    except RequestError as e:
        logger.error(f"Failed to create Tenant {name}: {str(e)}")
        raise

def get_or_create_custom_field(nb, field_name, field_type, field_description, object_types, field_choices=None):
    try:
        custom_field = nb.extras.custom_fields.get(name=field_name)
        if custom_field:
            logger.info(f"Found existing custom field: {field_name}")
            return custom_field
    except Exception as e:
        logger.debug(f"Error getting custom field {field_name}: {str(e)}")

    logger.info(f"Creating new custom field: {field_name}")
    field_data = {
        'name': field_name,
        'label': field_name.replace('_', ' ').title(),
        'type': field_type,
        'description': field_description,
        'object_types': object_types,
        'required': False,
        'default': None
    }
    if field_choices:
        field_data['choices'] = field_choices

    return nb.extras.custom_fields.create(**field_data)

def get_or_create_prefix(nb, prefix_value, defaults, subscription_name=None, subscription_id=None, aggregate_id=None, role_id=None, tenant_id=None, site_id=None, tags=None, status='active', is_pool=False):
    try:
        existing_prefixes = nb.ipam.prefixes.filter(prefix=prefix_value)
        
        if existing_prefixes:
            logger.info(f"Found existing prefix: {prefix_value}")
            prefix = list(existing_prefixes)[0]
            
            needs_update = False
            for key, value in defaults.items():
                if key == 'parent':  
                    continue
                current_value = getattr(prefix, key, None)
                if current_value != value:
                    setattr(prefix, key, value)
                    needs_update = True
            
            if subscription_name and subscription_id:
                custom_fields = getattr(prefix, 'custom_fields', {}) or {}
                azure_subscription_value = subscription_name
                
                existing_value = custom_fields.get('azure_subscription', '')
                if existing_value != azure_subscription_value or re.search(r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}', existing_value, re.IGNORECASE):
                    custom_fields['azure_subscription'] = azure_subscription_value
                    custom_fields['azure_subscription_url'] = f"https://portal.azure.com/#@/subscription/{subscription_id}/overview"
                    prefix.custom_fields = custom_fields
                    needs_update = True
                    logger.debug(f"Forced update of azure_subscription to clean value: {azure_subscription_value}")
            
            if aggregate_id and getattr(prefix, 'aggregate', None) != aggregate_id:
                prefix.aggregate = aggregate_id
                needs_update = True
            
            if role_id and getattr(prefix, 'role', None) != role_id:
                prefix.role = role_id
                needs_update = True
            
            if tenant_id and getattr(prefix, 'tenant', None) != tenant_id:
                prefix.tenant = tenant_id
                needs_update = True
            
            if site_id and getattr(prefix, 'site', None) != site_id:
                prefix.site = site_id
                needs_update = True
            
            if tags and set(tag.id for tag in prefix.tags) != set(tag['id'] for tag in tags):
                prefix.tags = tags
                needs_update = True
            
            if prefix.status != status:
                prefix.status = status
                needs_update = True
            
            if prefix.is_pool != is_pool:
                prefix.is_pool = is_pool
                needs_update = True
            
            if needs_update:
                prefix.save()
                logger.info(f"Updated prefix: {prefix_value}")
                
            return prefix, False
    except AttributeError as e:
        logger.error(f"Attribute error when updating prefix {prefix_value}: {str(e)}")
    except Exception as e:
        logger.debug(f"Error checking for existing prefix {prefix_value}: {str(e)}")
    
    try:
        logger.info(f"Creating new prefix: {prefix_value}")
        
        if subscription_name and subscription_id:
            if 'custom_fields' not in defaults:
                defaults['custom_fields'] = {}
            defaults['custom_fields']['azure_subscription'] = subscription_name
            defaults['custom_fields']['azure_subscription_url'] = f"https://portal.azure.com/#@/subscription/{subscription_id}/overview"
        
        if aggregate_id:
            defaults['aggregate'] = aggregate_id
        if role_id:
            defaults['role'] = role_id
        if tenant_id:
            defaults['tenant'] = tenant_id
        if site_id:
            defaults['site'] = site_id
        if tags:
            defaults['tags'] = tags
        
        defaults['status'] = status
        defaults['is_pool'] = is_pool
        
        return nb.ipam.prefixes.create(
            prefix=prefix_value,
            **defaults
        ), True
    except RequestError as e:
        if "Duplicate prefix found" in str(e):
            logger.warning(f"Duplicate prefix found: {prefix_value}. Attempting to retrieve existing prefix.")
            try:
                existing_prefixes = nb.ipam.prefixes.filter(prefix=prefix_value)
                if existing_prefixes:
                    prefix = list(existing_prefixes)[0]
                    logger.info(f"Retrieved existing prefix: {prefix_value}")
                    return prefix, False
            except Exception as inner_e:
                logger.error(f"Error retrieving duplicate prefix {prefix_value}: {str(inner_e)}")
        raise

def setup_rirs_and_aggregates(nb, config):
    rirs_config = config.get('rirs', [])
    aggregates_config = config.get('aggregates', [])
    
    rir_map = {}
    for rir in rirs_config:
        rir_tags = []
        for tag_item in rir.get('tags', []):
            tag = get_or_create_tag(nb, tag_item)
            if tag:
                rir_tags.append({'id': tag.id})
        
        created_rir = get_or_create_rir(
            nb,
            name=rir.get('name'),
            slug=rir.get('slug'),
            description=rir.get('description', ''),
            is_private=rir.get('is_private', False),
            tags=rir_tags
        )
        rir_map[rir['name']] = created_rir.id
    
    aggregate_map = {}
    for agg in aggregates_config:
        rir_id = rir_map.get(agg.get('rir'))
        if not rir_id:
            logger.error(f"RIR {agg.get('rir')} not found for aggregate {agg.get('prefix')}")
            continue
        
        agg_tags = []
        agg_tag_names = []  # Store lowercase tag names for filtering
        for tag_item in agg.get('tags', []):
            tag = get_or_create_tag(nb, tag_item)
            if tag:
                agg_tags.append({'id': tag.id})
                agg_tag_names.append(tag.name.lower())
        
        created_agg = get_or_create_aggregate(
            nb,
            prefix=agg.get('prefix'),
            rir_id=rir_id,
            description=agg.get('description', ''),
            tags=agg_tags
        )
        aggregate_map[agg.get('prefix')] = {
            'id': created_agg.id,
            'tags': agg_tags,
            'tag_names': agg_tag_names,  # For efficient filter checks
            'rir_id': rir_id
        }
    
    return aggregate_map

def setup_ipam_roles(nb, config):
    roles_config = config.get('ipam_roles', [])
    role_map = {}
    
    for role in roles_config:
        role_tags = []
        for tag_item in role.get('tags', []):
            tag = get_or_create_tag(nb, tag_item)
            if tag:
                role_tags.append({'id': tag.id})
        
        created_role = get_or_create_ipam_role(
            nb,
            name=role.get('name'),
            slug=role.get('slug'),
            description=role.get('description',
